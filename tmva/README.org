* Files
- path to root files
- tree name

* Methods
- TMVA supports many multivariate methods (see:
  TMVAClassification.C).  We use BDT and it's variants:
  - BDTA :: adaptive boost
  - BBDT :: ensemble/forest of BDTs
  - BDTG :: gradient boost
  - BDTB :: bagging
  - BDTD :: decorrelation + adaptive boost
  - BDTF :: use Fisher discriminant for node splitting

* TMVA training setup & configuration
(NB: Assumes Python as the programming language)
- Create instance & output file:
  : TMVA.Tools.Instance()
  : ofile = TFile.Open(fname, "recreate")
- use factory: colon separated options, semi-colon separated list.
  : factory = TMVA.Factory("TMVAClassification", ofile, "!V:!Silent:Color"+
  :                        ":DrawProgressBar:Transformations=I;D;P;G,D")
- add variables using factory:
  : factory.AddVariable("myvar1 := var1+var2", "F")
- can also add spectator variables, not used in training, but will be
  included in output tree.
  : factory.AddSpectator(..)
- get tree, and do branch renaming gymnastics.  Jacco's class makes it
  easier.
- Add signal/background event trees global event weights:
  : factory.AddSignalTree(<tree>, <wt>)
  : factory.AddBackgroundTree(<tree>, <wt>)
  Separate event trees can be given for training and testing:
  : factory.AddSignalTree(<tree1>, <wt1>, "Training")
  : factory.AddSignalTree(<tree2>, <wt2>. "Test")
- To learn how to add events by hand, see ~TMVAClassification.C~.
- Individual event weights:
  : factory.SetSignalWeightExpression("wt1*wt2")
  : factory.SetBackgroundWeightExpression("wt1*wt2")
  Variables in the expression should exist in the original event tree.
- Apply any selection cuts on signal/background:
  : factory.PrepareTrainingAndTestTree(sig_tcut, bkg_tcut,
  :     "nTrain_Signal=0:nTrain_Background=0:SplitMode=Random"+
  :     ":NormMode=NumEvents:!V")
  To use different number of signal and background events, use:
  : factory.PrepareTrainingAndTestTree(mycut, "NSigTrain=3000"+
  :     ":NBkgTrain=3000:NSigTest=3000:NBkgTest=3000:SplitMode=Random:!V")
- Book MVA methods, see source files like: [[http://root.cern.ch/gitweb?p=root.git;a=blob;f=tmva/src/MethodCuts.cxx;hb=HEAD][src/MethodCuts.cxx]], etc; or
  on [[http://tmva.sourceforge.net/optionRef.html][sourceforge]].  Example for BDTG:
  : factory.BookMethod(TMVA.Types.kBDT, "BDTG",
  :     "!H:!V:NTrees=1000:BoostType=Grad:Shrinkage=0.30:UseBaggedGrad"+
  :     ":GradBaggingFraction=0.6:SeparationType=GiniIndex:nCuts=20"+
  :     ":PruneMethod=CostComplexity:PruneStrength=50:NNodesMax=5")
- Train, test, evaluate, and save:
  : factory.TrainAllMethods()
  : factory.TestAllMethods()
  : factory.EvaluateAllMethods()
  : ofile.Close()
- By default weights written to in ~weights~ directory.
- Run ~TMVAGui.C~ or some such for result macros.
  : gROOT.ProcessLine("TMVAGui(\"%s\")" % outfname)
  : gApplication.Run()

* TMVA application setup & configuration
- Create reader:
  : reader = TMVA.Reader('!Color:!Silent')
- Add variables to reader:
  : reader.AddVariable(<name>, <ptr>)
  Use ~numpy~, ~array~, or ~ROOT.Double~ for the pointer.  Again,
  Jacco's class makes this less tedious.
- Add spectators:
  : reader.AddSpectator(<name>, <ptr>)
- Book methods (with weights file):
  : reader.BookMVA(<method_name>, <weights_file>)
- Prepare output tree.
  - Apply tree branch name transforms (see Jacco's code).
  - Add MVA output branch
  - Fill tree
- Evaluate MVA, fill MVA output.
  : reader.EvaluateMVA(<name>)
- Get efficiencies (optional?):
  : reader.FindCutsMVA(<name>)

* B_{s} → D_{s}K 3/fb dataset
/data/bfys/lbel/DsKntuples3fb/
- B2DX_withtagging_strip20_DVv33r8_3fb_magdown_BDTG_Bs.root
- B2DX_withtagging_strip20_DVv33r8_3fb_magup_BDTG_Bs.root

* Tasks [10/14]
** WInP Optimise BDT algorithms
   :LOGBOOK:
   - State "WInP"       from "TODO"       [2015-02-18 Wed 23:56]
   :END:
- Optimise by training on MC signal, but under performs on data
- Try s-weighted data, or reweighted MC
- Investigate old BDTG, vs new BDTG, vs BDTB.  As in, does the type of
  MVA have anything to do with it, or is it training samples.
- Check where MC deviates from data
  - compare base, less2, less3, logb, log3a, log3b
** TODO Add event weights
** TODO Implement cross-validation
** TODO Easy MVA application
- Use friend trees/event lists
** DONE Resolve vertex χ² variable disambiguity
   CLOSED: [2014-11-17 Mon 13:30]
- Vertex χ²/ndof
- Lifetime vertex χ²/ndof
** DONE Radial flight distance
   CLOSED: [2014-09-05 Fri 15:45]
- B_{s}: OWNPV - ENDVERTEX
- D_{s}: OWNPV - ENDVERTEX
** DONE How to minimum/maximum of in TMVA
   CLOSED: [2014-09-08 Mon 16:56]
- D_{s} children minimum track p_{T} and IP χ²
- D_{s} children & bachelor maximum track ghost probability
Use the functions: =Max$()=, =Min$()=.  However this doesn't work with
arbitrary branches, only takes a ~TTreeFormula~ argument.  So first
add a branch with needed variables as a vector, then call the function
in a formula.
** DONE Efficiency plots
   CLOSED: [2014-09-15 Mon 13:13]
BDT selection efficiency (for 3 diff arbitrary selections) for:
- decay time → acceptance
- decay time error → decay time resolution
- B_{s} mass → mass fit
** DONE List different training variable configs
   CLOSED: [2015-01-07 Wed 14:33]
- Include both RFD
** DONE Compare w/ & w/o log of input vars
   CLOSED: [2015-01-07 Wed 16:31]
Better with logarithm of IP χ² (log3a)
** DONE Efficiencies w/ & w/o truth-matching
   CLOSED: [2015-02-18 Wed 23:54]
[[notmuch:id:alpine.LRH.2.02.1412102018060.19203@lena.nikhef.nl][Niels's email on truth-matching]]
** DONE Metric for qualifying ROC curves
   CLOSED: [2015-02-18 Wed 23:55]
- area under the curve
- min. distance from the curve to (1,1)
- make ROC curves myself
- if not, scan ROC curves from TMVA
** DONE Own ROC curve
   CLOSED: [2015-01-09 Fri 14:03]
- correct scanning
- variable bins in python
** DONE Decorrelation, w/ or w/o
   CLOSED: [2015-01-08 Thu 13:19]
Do not use.  Too little gain, transformed variables difficult to
understand.

* Notes
** Training config
Sets of input variables:
- base :: variables
  - B_{s} :: DIRA, IP χ², decay vertex χ²/dof, radial flight distance (RFD)
  - bachelor :: IP χ², p_{T}
  - D_{s} :: minimum IP χ², decay vertex χ²/dof, RFD
  - tracks :: maximum track ghost probability, minimum D_{s} daughter
       track p_{T} & IP χ²
- less1a :: w/o D_{s} RFD
- less1b :: w/o B_{s} RFD
- less2 :: w/o either RFD variables
- less3 :: w/o bachelor IP χ²
- less4 :: w/o either RFD, and bachelor IP χ²
- deco1 :: w/ decorrelation of all variables
- deco2 :: w/ decorrelation of selected variables
  - both RFD
  - D_{s} minimum IP χ²
  - minimum D_{s} daughter IP χ²
- combi1 :: w/ decorrelation (3 vars), w/o D_{s} RFD
- combi2 :: w/ decorrelation (4 vars), w/o bachelor IP χ²
- combi3 :: w/ decorrelation (2 vars), w/o either RFD
- log :: w/ decorrelation (1 var), w/o either RFD, w/ logarithm of IP
     χ² and p_{T} variables
  - B_{s} IP χ²
  - bachelor p_{T}
  - D_{s} minimum IP χ²
- loga :: same as above, but w/ both RFD
- logb :: same as above, but w/o decorrelation
- log3 :: w/ decorrelation (1 var), w/o either RFD, w/ logarithm of IP
     χ² variables
  - B_{s} IP χ²
  - D_{s} minimum IP χ²
- log3b :: same as above, but w/o decorrelation
- log3a :: same as above, but w/o decorrelation, and includes both RFD
- max_diff :: same as above, w/ new experimental variable (Rose & me)
  - maximum difference b/w D_{s} daughter track p_{T}
- max_diffb :: same as above, but w/o decorrelation

*** Dependent variables (log3a)
Training:
- lab0_ENDVERTEX_CHI2
- lab0_ENDVERTEX_NDOF
- lab2_ENDVERTEX_CHI2
- lab2_ENDVERTEX_NDOF
- lab0_IPCHI2_OWNPV
- lab2_MINIPCHI2
- lab0_OWNPV_X
- lab0_ENDVERTEX_X
- lab0_OWNPV_Y
- lab0_ENDVERTEX_Y
- lab2_OWNPV_X
- lab2_ENDVERTEX_X
- lab2_OWNPV_Y
- lab2_ENDVERTEX_Y
- lab1_TRACK_GhostProb
- lab3_TRACK_GhostProb
- lab4_TRACK_GhostProb
- lab5_TRACK_GhostProb
- lab3_PT
- lab4_PT
- lab5_PT
- lab3_IPCHI2_OWNPV
- lab4_IPCHI2_OWNPV
- lab5_IPCHI2_OWNPV
- lab0_DIRA_OWNPV
- lab1_PT

Preselection:
- lab1_ID
- lab2_TAU
- lab2_FDCHI2_ORIVX
- lab0_Hlt1TrackAllL0Decision_TOS
- lab0_Hlt2Topo2BodyBBDTDecision_TOS
- lab0_Hlt2Topo3BodyBBDTDecision_TOS
- lab0_Hlt2Topo4BodyBBDTDecision_TOS
- lab0_Hlt2IncPhiDecision_TOS
- lab0_MM

Spectators:
- lab0_LifetimeFit_ctau
- lab0_TAU
- lab1_PIDK
- lab0_LifetimeFit_ctauErr
- lab0_TAUERR
- lab0_P
- lab0_PT
- lab0_PE
- lab0_PX
- lab0_PY
- lab0_PZ
- lab1_P
- lab1_PT
- lab1_PE
- lab1_PX
- lab1_PY
- lab1_PZ
- lab2_P
- lab2_PT
- lab2_PE
- lab2_PX
- lab2_PY
- lab2_PZ
- lab2_MM
